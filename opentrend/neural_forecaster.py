"""
opentrend/neural_forecaster.py
Breakthrough & Early-Signal Fashion Prediction Engine

A high-accuracy hybrid AI system combining:
- Deep Neural Networks (LSTM, Transformer)
- Computer Vision (ResNet50, Vision Transformer)
- Ensemble Methods (Stacking, Weighted Voting)
- Prophet Time-Series Forecasting
- Early Signal Detection Algorithms

Architecture:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PREDICTION ENGINE                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ ResNet50â”‚   â”‚  LSTM   â”‚   â”‚Transformerâ”‚ â”‚ Prophet â”‚         â”‚
â”‚  â”‚ Vision  â”‚   â”‚ Temporalâ”‚   â”‚ Attention â”‚ â”‚  Trend  â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜         â”‚
â”‚       â”‚             â”‚              â”‚            â”‚               â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                          â”‚                                       â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                  â”‚   ENSEMBLE    â”‚                              â”‚
â”‚                  â”‚   COMBINER    â”‚                              â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                          â”‚                                       â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                  â”‚  EARLY SIGNAL â”‚                              â”‚
â”‚                  â”‚   DETECTOR    â”‚                              â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                          â”‚                                       â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                  â”‚  PREDICTION   â”‚                              â”‚
â”‚                  â”‚   + SCORE     â”‚                              â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Usage:
    engine = BreakthroughPredictionEngine()
    predictions = engine.predict(trends_data, images_path)
    engine.generate_report()
"""

from __future__ import annotations

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, TensorDataset
from pathlib import Path
from datetime import datetime, timedelta
from dataclasses import dataclass, field, asdict
from typing import List, Dict, Optional, Tuple, Any
import json
import logging
import warnings

warnings.filterwarnings('ignore')

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Check for GPU
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


# =============================================================================
# NEURAL NETWORK ARCHITECTURES
# =============================================================================

class LSTMTrendPredictor(nn.Module):
    """
    LSTM-based temporal pattern learning for trend prediction.
    Captures long-term dependencies in fashion trend data.
    """
    
    def __init__(
        self,
        input_size: int = 1,
        hidden_size: int = 128,
        num_layers: int = 3,
        dropout: float = 0.2,
        bidirectional: bool = True
    ):
        super().__init__()
        
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.bidirectional = bidirectional
        
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            dropout=dropout,
            bidirectional=bidirectional,
            batch_first=True
        )
        
        direction_factor = 2 if bidirectional else 1
        
        self.fc = nn.Sequential(
            nn.Linear(hidden_size * direction_factor, 64),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1)
        )
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # x shape: (batch, seq_len, input_size)
        lstm_out, _ = self.lstm(x)
        # Take last timestep
        last_hidden = lstm_out[:, -1, :]
        output = self.fc(last_hidden)
        return output


class TransformerTrendPredictor(nn.Module):
    """
    Transformer-based attention model for trend prediction.
    Excels at capturing complex temporal relationships.
    """
    
    def __init__(
        self,
        input_size: int = 1,
        d_model: int = 64,
        nhead: int = 4,
        num_layers: int = 2,
        dropout: float = 0.1
    ):
        super().__init__()
        
        self.input_projection = nn.Linear(input_size, d_model)
        self.pos_encoder = PositionalEncoding(d_model, dropout)
        
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=d_model * 4,
            dropout=dropout,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        self.fc = nn.Sequential(
            nn.Linear(d_model, 32),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(32, 1)
        )
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # x shape: (batch, seq_len, input_size)
        x = self.input_projection(x)
        x = self.pos_encoder(x)
        x = self.transformer(x)
        # Global average pooling over sequence
        x = x.mean(dim=1)
        return self.fc(x)


class PositionalEncoding(nn.Module):
    """Positional encoding for Transformer."""
    
    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 500):
        super().__init__()
        self.dropout = nn.Dropout(p=dropout)
        
        position = torch.arange(max_len).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))
        pe = torch.zeros(1, max_len, d_model)
        pe[0, :, 0::2] = torch.sin(position * div_term)
        pe[0, :, 1::2] = torch.cos(position * div_term)
        self.register_buffer('pe', pe)
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = x + self.pe[:, :x.size(1), :]
        return self.dropout(x)


class VisionTrendAnalyzer(nn.Module):
    """
    Vision-based trend analysis using pre-trained features.
    Detects visual patterns that indicate emerging trends.
    """
    
    def __init__(self, feature_dim: int = 2048, hidden_dim: int = 512):
        super().__init__()
        
        self.feature_processor = nn.Sequential(
            nn.Linear(feature_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, 64)
        )
        
        self.trend_head = nn.Linear(64, 1)
        self.novelty_head = nn.Linear(64, 1)  # Detect visual novelty
        
    def forward(self, features: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        x = self.feature_processor(features)
        trend_score = torch.sigmoid(self.trend_head(x))
        novelty_score = torch.sigmoid(self.novelty_head(x))
        return trend_score, novelty_score


class EarlySignalDetector(nn.Module):
    """
    Specialized network for detecting early trend signals.
    Uses anomaly detection and gradient analysis.
    """
    
    def __init__(self, input_size: int = 52):
        super().__init__()
        
        # Convolutional feature extraction
        self.conv1d = nn.Sequential(
            nn.Conv1d(1, 32, kernel_size=5, padding=2),
            nn.ReLU(),
            nn.Conv1d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.AdaptiveAvgPool1d(16)
        )
        
        # Gradient analysis
        self.gradient_fc = nn.Sequential(
            nn.Linear(input_size - 1, 32),
            nn.ReLU(),
            nn.Linear(32, 16)
        )
        
        # Combined analysis
        self.combined = nn.Sequential(
            nn.Linear(64 * 16 + 16, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 32),
            nn.ReLU(),
            nn.Linear(32, 3)  # Output: [is_emerging, confidence, time_to_peak]
        )
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # x shape: (batch, seq_len)
        batch_size = x.size(0)
        
        # Conv features
        conv_input = x.unsqueeze(1)  # (batch, 1, seq_len)
        conv_features = self.conv1d(conv_input).view(batch_size, -1)
        
        # Gradient features (first derivative)
        gradients = x[:, 1:] - x[:, :-1]
        gradient_features = self.gradient_fc(gradients)
        
        # Combine
        combined = torch.cat([conv_features, gradient_features], dim=1)
        output = self.combined(combined)
        
        return output


# =============================================================================
# ENSEMBLE COMBINER
# =============================================================================

class EnsembleCombiner:
    """
    Combines predictions from multiple models using weighted voting.
    Learns optimal weights based on historical accuracy.
    """
    
    def __init__(self):
        self.model_weights = {
            'lstm': 0.25,
            'transformer': 0.25,
            'prophet': 0.30,
            'vision': 0.10,
            'early_signal': 0.10
        }
        self.accuracy_history = {k: [] for k in self.model_weights}
        
    def update_weights(self, model_accuracies: Dict[str, float]):
        """Update weights based on recent accuracy."""
        total = sum(model_accuracies.values())
        if total > 0:
            for model, acc in model_accuracies.items():
                if model in self.model_weights:
                    self.model_weights[model] = acc / total
                    self.accuracy_history[model].append(acc)
    
    def combine(self, predictions: Dict[str, float]) -> Tuple[float, float]:
        """
        Combine predictions with confidence score.
        
        Returns:
            (combined_prediction, confidence_score)
        """
        weighted_sum = 0.0
        weight_sum = 0.0
        
        for model, pred in predictions.items():
            if model in self.model_weights:
                weight = self.model_weights[model]
                weighted_sum += pred * weight
                weight_sum += weight
        
        combined = weighted_sum / weight_sum if weight_sum > 0 else 0.0
        
        # Confidence based on prediction agreement
        preds = list(predictions.values())
        std = np.std(preds) if len(preds) > 1 else 0
        confidence = max(0, 1 - std / 50)  # Lower std = higher confidence
        
        return combined, confidence


# =============================================================================
# DATA STRUCTURES
# =============================================================================

@dataclass
class TrendPrediction:
    """Complete prediction for a single trend."""
    name: str
    category: str
    current_value: float
    predicted_value: float
    growth_percent: float
    confidence: float
    is_breakthrough: bool
    time_to_peak_weeks: int
    risk_level: str  # low, medium, high
    model_contributions: Dict[str, float] = field(default_factory=dict)
    signals: List[str] = field(default_factory=list)
    
    @property
    def recommendation(self) -> str:
        if self.is_breakthrough and self.confidence > 0.7:
            return "INVEST_NOW"
        elif self.growth_percent > 20 and self.confidence > 0.6:
            return "PRIORITIZE"
        elif self.growth_percent > 0:
            return "MONITOR"
        else:
            return "AVOID"


# =============================================================================
# MAIN PREDICTION ENGINE
# =============================================================================

class BreakthroughPredictionEngine:
    """
    Advanced Fashion Trend Prediction Engine.
    
    Combines multiple AI models for high-accuracy breakthrough detection:
    - LSTM for temporal patterns
    - Transformer for attention-based analysis
    - Vision analysis for visual trend detection
    - Prophet for time-series forecasting
    - Early signal detector for emerging trends
    
    Features:
    - Ensemble prediction combining all models
    - Confidence scoring based on model agreement
    - Early signal detection for breakthrough trends
    - Risk assessment and recommendations
    """
    
    def __init__(
        self,
        lstm_hidden: int = 128,
        transformer_d_model: int = 64,
        device: str = None
    ):
        self.device = torch.device(device) if device else DEVICE
        
        logger.info(f"Initializing Breakthrough Prediction Engine on {self.device}")
        
        # Initialize neural networks
        self.lstm = LSTMTrendPredictor(hidden_size=lstm_hidden).to(self.device)
        self.transformer = TransformerTrendPredictor(d_model=transformer_d_model).to(self.device)
        self.vision_analyzer = VisionTrendAnalyzer().to(self.device)
        self.early_detector = EarlySignalDetector().to(self.device)
        
        # Ensemble combiner
        self.ensemble = EnsembleCombiner()
        
        # Prophet (lazy load)
        self._forecaster = None
        
        # Feature extractor (lazy load)
        self._feature_extractor = None
        
        # Results storage
        self.predictions: List[TrendPrediction] = []
        
        logger.info("Engine initialized with 5 AI models")
        
    @property
    def forecaster(self):
        """Lazy load Prophet forecaster."""
        if self._forecaster is None:
            from forecasting.prophet_predictor import TrendForecaster
            self._forecaster = TrendForecaster()
        return self._forecaster
    
    @property
    def feature_extractor(self):
        """Lazy load ResNet50 feature extractor."""
        if self._feature_extractor is None:
            from vision.feature_extractor import FashionFeatureExtractor
            self._feature_extractor = FashionFeatureExtractor()
        return self._feature_extractor
    
    def _train_models(self, data: Dict[str, pd.DataFrame], epochs: int = 50):
        """
        Train neural network models on historical data.
        
        Args:
            data: Dict mapping trend names to DataFrames with 'ds' and 'y' columns
            epochs: Number of training epochs
        """
        logger.info(f"Training models on {len(data)} trends for {epochs} epochs")
        
        # Prepare training data
        all_sequences = []
        all_targets = []
        
        for name, df in data.items():
            values = df['y'].values
            
            # Create sequences (52 weeks input, 1 week output)
            seq_len = 52
            for i in range(len(values) - seq_len):
                all_sequences.append(values[i:i+seq_len])
                all_targets.append(values[i+seq_len])
        
        if not all_sequences:
            logger.warning("No training data available")
            return
        
        X = torch.tensor(np.array(all_sequences), dtype=torch.float32).unsqueeze(-1)
        y = torch.tensor(np.array(all_targets), dtype=torch.float32).unsqueeze(-1)
        
        dataset = TensorDataset(X, y)
        loader = DataLoader(dataset, batch_size=32, shuffle=True)
        
        # Train LSTM
        self._train_model(self.lstm, loader, epochs, "LSTM")
        
        # Train Transformer
        self._train_model(self.transformer, loader, epochs, "Transformer")
        
        # Train Early Signal Detector
        X_flat = X.squeeze(-1)
        early_dataset = TensorDataset(X_flat, y)
        early_loader = DataLoader(early_dataset, batch_size=32, shuffle=True)
        self._train_early_detector(early_loader, epochs)
        
        logger.info("Model training complete")
    
    def _train_model(self, model: nn.Module, loader: DataLoader, epochs: int, name: str):
        """Train a single model."""
        model.train()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        criterion = nn.MSELoss()
        
        for epoch in range(epochs):
            total_loss = 0
            for X_batch, y_batch in loader:
                X_batch = X_batch.to(self.device)
                y_batch = y_batch.to(self.device)
                
                optimizer.zero_grad()
                output = model(X_batch)
                loss = criterion(output, y_batch)
                loss.backward()
                optimizer.step()
                
                total_loss += loss.item()
            
            if (epoch + 1) % 10 == 0:
                logger.info(f"  {name} Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(loader):.4f}")
    
    def _train_early_detector(self, loader: DataLoader, epochs: int):
        """Train early signal detector."""
        self.early_detector.train()
        optimizer = torch.optim.Adam(self.early_detector.parameters(), lr=0.001)
        
        for epoch in range(epochs):
            for X_batch, _ in loader:
                X_batch = X_batch.to(self.device)
                
                optimizer.zero_grad()
                output = self.early_detector(X_batch)
                
                # Self-supervised: predict gradient direction
                gradients = X_batch[:, 1:] - X_batch[:, :-1]
                avg_gradient = gradients[:, -10:].mean(dim=1)
                targets = (avg_gradient > 0).float().unsqueeze(-1)
                
                loss = F.binary_cross_entropy_with_logits(output[:, :1], targets)
                loss.backward()
                optimizer.step()
    
    def _predict_lstm(self, sequence: np.ndarray) -> float:
        """Get LSTM prediction."""
        self.lstm.eval()
        with torch.no_grad():
            x = torch.tensor(sequence, dtype=torch.float32).unsqueeze(0).unsqueeze(-1).to(self.device)
            pred = self.lstm(x)
            return pred.item()
    
    def _predict_transformer(self, sequence: np.ndarray) -> float:
        """Get Transformer prediction."""
        self.transformer.eval()
        with torch.no_grad():
            x = torch.tensor(sequence, dtype=torch.float32).unsqueeze(0).unsqueeze(-1).to(self.device)
            pred = self.transformer(x)
            return pred.item()
    
    def _predict_prophet(self, df: pd.DataFrame, periods: int = 26) -> float:
        """Get Prophet prediction."""
        from forecasting.prophet_predictor import TrendForecaster
        forecaster = TrendForecaster()
        forecaster.fit(df)
        forecast = forecaster.forecast(periods=periods)
        return forecast['forecast'].iloc[-1]
    
    def _detect_early_signals(self, sequence: np.ndarray) -> Dict[str, Any]:
        """Detect early breakthrough signals."""
        self.early_detector.eval()
        with torch.no_grad():
            x = torch.tensor(sequence, dtype=torch.float32).unsqueeze(0).to(self.device)
            output = self.early_detector(x)
            
            is_emerging = torch.sigmoid(output[0, 0]).item()
            confidence = torch.sigmoid(output[0, 1]).item()
            time_to_peak = int(output[0, 2].item() * 26)  # Scale to weeks
            
            return {
                'is_emerging': is_emerging > 0.5,
                'emergence_score': is_emerging,
                'confidence': confidence,
                'time_to_peak_weeks': max(1, min(52, time_to_peak))
            }
    
    def _analyze_vision_features(self, features: np.ndarray) -> Dict[str, float]:
        """Analyze visual features for trend signals."""
        self.vision_analyzer.eval()
        with torch.no_grad():
            x = torch.tensor(features, dtype=torch.float32).to(self.device)
            if x.dim() == 1:
                x = x.unsqueeze(0)
            
            trend_score, novelty_score = self.vision_analyzer(x)
            
            return {
                'visual_trend_score': trend_score.mean().item(),
                'novelty_score': novelty_score.mean().item()
            }
    
    def predict(
        self,
        trends_data: Dict[str, pd.DataFrame],
        images_path: Optional[str] = None,
        train: bool = True
    ) -> List[TrendPrediction]:
        """
        Generate predictions for all trends.
        
        Args:
            trends_data: Dict mapping trend names to DataFrames with 'ds' and 'y' columns
            images_path: Optional path to fashion images for visual analysis
            train: Whether to train models on the data first
            
        Returns:
            List of TrendPrediction objects
        """
        logger.info(f"Starting prediction for {len(trends_data)} trends")
        
        # Train models if requested
        if train:
            self._train_models(trends_data, epochs=30)
        
        # Extract visual features if images provided
        visual_features = None
        if images_path:
            logger.info(f"Extracting visual features from {images_path}")
            images = list(Path(images_path).rglob("*.jpg")) + list(Path(images_path).rglob("*.png"))
            if images:
                visual_features = self.feature_extractor.extract_batch([str(p) for p in images[:100]])
        
        predictions = []
        
        for name, df in trends_data.items():
            logger.info(f"Processing: {name}")
            
            values = df['y'].values
            sequence = values[-52:]  # Last year
            current = values[-1]
            
            # Get predictions from each model
            model_preds = {}
            
            # LSTM prediction
            lstm_pred = self._predict_lstm(sequence)
            model_preds['lstm'] = lstm_pred
            
            # Transformer prediction
            transformer_pred = self._predict_transformer(sequence)
            model_preds['transformer'] = transformer_pred
            
            # Prophet prediction
            prophet_pred = self._predict_prophet(df)
            model_preds['prophet'] = prophet_pred
            
            # Early signal detection
            early_signals = self._detect_early_signals(sequence)
            model_preds['early_signal'] = early_signals['emergence_score'] * 100
            
            # Vision analysis (if available)
            if visual_features is not None:
                vision_analysis = self._analyze_vision_features(visual_features)
                model_preds['vision'] = vision_analysis['visual_trend_score'] * 100
            
            # Ensemble combination
            combined_pred, confidence = self.ensemble.combine(model_preds)
            
            # Calculate growth
            growth = ((combined_pred - current) / max(current, 1)) * 100
            
            # Determine if breakthrough
            is_breakthrough = (
                early_signals['is_emerging'] and 
                growth > 15 and 
                confidence > 0.6
            )
            
            # Risk assessment
            if confidence > 0.8:
                risk = "low"
            elif confidence > 0.5:
                risk = "medium"
            else:
                risk = "high"
            
            # Generate signals
            signals = []
            if early_signals['is_emerging']:
                signals.append("EMERGING_TREND_DETECTED")
            if growth > 30:
                signals.append("HIGH_GROWTH_MOMENTUM")
            if confidence > 0.8:
                signals.append("HIGH_MODEL_AGREEMENT")
            if values[-4:].mean() > values[-12:-4].mean():
                signals.append("RECENT_ACCELERATION")
            
            prediction = TrendPrediction(
                name=name,
                category="fashion",
                current_value=round(current, 1),
                predicted_value=round(combined_pred, 1),
                growth_percent=round(growth, 1),
                confidence=round(confidence, 3),
                is_breakthrough=is_breakthrough,
                time_to_peak_weeks=early_signals['time_to_peak_weeks'],
                risk_level=risk,
                model_contributions=model_preds,
                signals=signals
            )
            
            predictions.append(prediction)
        
        # Sort by breakthrough potential
        predictions.sort(key=lambda x: (x.is_breakthrough, x.growth_percent), reverse=True)
        
        self.predictions = predictions
        logger.info(f"Generated {len(predictions)} predictions")
        
        return predictions
    
    def get_breakthroughs(self) -> List[TrendPrediction]:
        """Get only breakthrough predictions."""
        return [p for p in self.predictions if p.is_breakthrough]
    
    def get_accuracy_metrics(self) -> Dict[str, float]:
        """Calculate accuracy metrics (requires validation data)."""
        if not self.predictions:
            return {}
        
        # Calculate average confidence as proxy for accuracy
        avg_confidence = np.mean([p.confidence for p in self.predictions])
        
        # High confidence predictions
        high_conf = [p for p in self.predictions if p.confidence > 0.7]
        
        return {
            'average_confidence': round(avg_confidence, 3),
            'high_confidence_count': len(high_conf),
            'breakthrough_count': len(self.get_breakthroughs()),
            'total_predictions': len(self.predictions)
        }
    
    def generate_report(self, output_path: str = "breakthrough_forecast.json") -> str:
        """Generate comprehensive prediction report."""
        
        report = {
            'generated_at': datetime.now().isoformat(),
            'engine': 'BreakthroughPredictionEngine',
            'models': ['LSTM', 'Transformer', 'Prophet', 'VisionAnalyzer', 'EarlySignalDetector'],
            'metrics': self.get_accuracy_metrics(),
            'breakthroughs': [asdict(p) for p in self.get_breakthroughs()],
            'all_predictions': [asdict(p) for p in self.predictions],
            'model_weights': self.ensemble.model_weights
        }
        
        with open(output_path, 'w') as f:
            json.dump(report, f, indent=2)
        
        logger.info(f"Report saved to {output_path}")
        return output_path
    
    def print_summary(self):
        """Print prediction summary."""
        print("\n" + "="*70)
        print("ğŸ§  BREAKTHROUGH PREDICTION ENGINE - RESULTS")
        print("="*70)
        
        metrics = self.get_accuracy_metrics()
        print(f"\nğŸ“Š Metrics:")
        print(f"   Average Confidence: {metrics.get('average_confidence', 0):.1%}")
        print(f"   High-Confidence Predictions: {metrics.get('high_confidence_count', 0)}")
        print(f"   Breakthroughs Detected: {metrics.get('breakthrough_count', 0)}")
        
        print(f"\nğŸš€ BREAKTHROUGH PREDICTIONS:")
        print("-"*60)
        
        for i, p in enumerate(self.get_breakthroughs()[:5], 1):
            print(f"  {i}. {p.name}")
            print(f"     Growth: {p.growth_percent:+.1f}% | Confidence: {p.confidence:.1%}")
            print(f"     Signals: {', '.join(p.signals)}")
            print(f"     Recommendation: {p.recommendation}")
        
        print("="*70)


# =============================================================================
# DEMO / MAIN
# =============================================================================

if __name__ == "__main__":
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     BREAKTHROUGH & EARLY-SIGNAL FASHION PREDICTION ENGINE                â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                           â•‘
â•‘  AI Models:                                                               â•‘
â•‘  â€¢ LSTM Neural Network (Temporal Patterns)                                â•‘
â•‘  â€¢ Transformer Network (Attention-Based)                                  â•‘
â•‘  â€¢ Prophet (Time-Series Forecasting)                                      â•‘
â•‘  â€¢ Vision Analyzer (ResNet50 Features)                                    â•‘
â•‘  â€¢ Early Signal Detector (Breakthrough Detection)                         â•‘
â•‘                                                                           â•‘
â•‘  Features:                                                                â•‘
â•‘  â€¢ Ensemble Prediction with Weighted Voting                               â•‘
â•‘  â€¢ Confidence Scoring (Model Agreement)                                   â•‘
â•‘  â€¢ Automatic Breakthrough Detection                                       â•‘
â•‘  â€¢ Risk Assessment & Recommendations                                      â•‘
â•‘                                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    print("Initializing engine...")
    engine = BreakthroughPredictionEngine()
    print(f"Engine ready on {engine.device}")
    print("\nUsage:")
    print("  predictions = engine.predict(trends_data)")
    print("  engine.print_summary()")
    print("  engine.generate_report()")
